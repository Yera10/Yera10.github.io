<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>딥러닝 on 이세상의 모든 노트</title><link>https://yera10.github.io/docs/mystudy/deep-learning-study/</link><description>Recent content in 딥러닝 on 이세상의 모든 노트</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://yera10.github.io/docs/mystudy/deep-learning-study/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://yera10.github.io/docs/mystudy/deep-learning-study/historical_review/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/historical_review/</guid><description>&lt;h1 id="historical-review">
 Historical Review
 &lt;a class="anchor" href="#historical-review">#&lt;/a>
&lt;/h1>
&lt;ul>
&lt;li>2012 - AlexNet (패러다임 쇼크!)&lt;/li>
&lt;li>2013 - DQN (알파고를 만든 알고리즘)&lt;/li>
&lt;li>2014 - Encoder/Decoder, Adam&lt;/li>
&lt;li>2015 - GAN, ResNet&lt;/li>
&lt;li>2016 -&lt;/li>
&lt;li>2017 - Transformer (Attention Is All You Need)&lt;/li>
&lt;li>2018 - Bert&lt;/li>
&lt;li>2019 - Big Language Models (GPT-X)&lt;/li>
&lt;li>2020 - Self-Supervised Learning (SimCLR)&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://dennybritz.com/posts/deep-learning-ideas-that-stood-the-test-of-time/">Further Reading and Reference&lt;/a>&lt;/p>
&lt;h2 id="alexnet-2012alexnet">
 &lt;a href="../alexnet">AlexNet (2012)&lt;/a>
 &lt;a class="anchor" href="#alexnet-2012alexnet">#&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>AlexNet은 딥러닝과 AI 연구의 붐을 일으킨 알고리즘으로 여겨졌다&lt;/li>
&lt;li>Yann LeCun이 개발한 초기 LeNet에 기초한 CNN이다&lt;/li>
&lt;li>알고리즘을 발전시키고, GPU 성능을 통해 기존 방법들 보다 ImageNet 데이터를 분류하는데 훨씬 뛰어난 성능을 보였다.&lt;/li>
&lt;li>neural network이 실제로 작동한다는 것을 증명해낸 것이다.&lt;/li>
&lt;li>또한, Alexnet은 Dropout을 처음 적용한 모델이기도 하다.&lt;/li>
&lt;li>Dropout은 이후 모든 종류의 딥러닝모델의 일반화 성능을 향상시키는데 중요한 요소가 되었다.&lt;/li>
&lt;li>AlexNet의 컨볼루션 레이어, ReLU, max-pooling 아키텍처는 이후 Computer Vision의 표준이 되었습니다.&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">논문&lt;/a>&lt;/p></description></item><item><title>AlexNet 논문</title><link>https://yera10.github.io/docs/mystudy/deep-learning-study/paper_alexnet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/paper_alexnet/</guid><description>&lt;h1 id="imagenet-classification-with-deep-convolutional-neural-networks">
 ImageNet Classification with Deep Convolutional Neural Networks
 &lt;a class="anchor" href="#imagenet-classification-with-deep-convolutional-neural-networks">#&lt;/a>
&lt;/h1>
&lt;p>&lt;a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">paper&lt;/a>&lt;/p>
&lt;h2 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>ImageNet LSVRC-2010 (1,200,000장의 고해상도 이미지들)를 1000개의 클래스로 분류하는 CNN 모델&lt;/li>
&lt;li>기존 SOTA보다 향상된 성능&lt;/li>
&lt;li>6천만개의 파라미터, 65만개의 뉴런으로 이루어져있고, 5개의 Conv-layer와 3개의 FC-layer로 구성되어있다. (최종은 1000-way softmax)&lt;/li>
&lt;li>빠르게 훈련시키기 위해 비포화 뉴런과 GPU 구현을 사용&lt;/li>
&lt;li>FC-layer에서 오버피팅을 줄이기 위해 dropout 방법 적용&lt;/li>
&lt;li>또한, Alexnet의 변형은 ILSVRC-2012에서 오류율 15.3%로 우승한 딥러닝 신경망 아키텍처이다.&lt;/li>
&lt;/ul>
&lt;h2 id="introduction">
 Introduction
 &lt;a class="anchor" href="#introduction">#&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>이 논문의 기여도
&lt;ul>
&lt;li>ImageNet데이터로 훈련한 CNN모델로 이 데이터셋에 대한 최고의 성능에 달성&lt;/li>
&lt;li>2D conv에 최적화된 GPU 구현과 공개&lt;/li>
&lt;li>성능을 향상시키고 훈련시간을 단축시키는 몇 가지 특징들이 있다 (Section 3)&lt;/li>
&lt;li>오버피팅을 방지하는 몇 가지 기술들 (Section 4)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>이당시 2개의 GTX 580 3GB GPUs로 훈련했을 때, 5~6일 소요됐다.&lt;/li>
&lt;/ul>
&lt;h2 id="dataset-imagenet">
 Dataset: ImageNet
 &lt;a class="anchor" href="#dataset-imagenet">#&lt;/a>
&lt;/h2>
&lt;ul>
&lt;li>약 22,000개의 카테고리로 이루어진 1천5백만개 이상의 라벨이 있는 고해상도 이미지이다.&lt;/li>
&lt;li>top-5 error rate는 뭐지?&lt;/li>
&lt;li>ImageNet은 다양한 해상도의 이미지로 구성되어있지만, AlexNet은 일정한 차원으로 입력해야 하므로, 256x256 고정으로 다운샘플해야 한다.&lt;/li>
&lt;li>직사각형 이미지에 대해서, 짧은 변을 256으로 resize하고, 중앙 256x256을 잘라내는 작업을 했음.&lt;/li>
&lt;/ul>
&lt;h2 id="architecture">
 Architecture
 &lt;a class="anchor" href="#architecture">#&lt;/a>
&lt;/h2>
&lt;p>AlexNet의 아키텍처는 아래와 같이 &lt;!-- raw HTML omitted -->&lt;strong>Conv layer 5 계층 + FC layer 3 계층&lt;/strong>&lt;!-- raw HTML omitted -->으로 구성되어 있고, 4가지 특징을 가지고 있다.&lt;/p></description></item><item><title>AlexNet 구현 (Pytorch)</title><link>https://yera10.github.io/docs/mystudy/deep-learning-study/alexnet-in-pytorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/alexnet-in-pytorch/</guid><description>&lt;h1 id="alexnet-구현">
 Alexnet 구현
 &lt;a class="anchor" href="#alexnet-%ea%b5%ac%ed%98%84">#&lt;/a>
&lt;/h1>
&lt;p>최대한 이해한대로 구현해보았다. 학습해서 결과를 보는 것보다는 모델 구현에 중점을 두어 학습과정은 다소 빈약하다.&lt;/p>
&lt;h2 id="라이브러리-호출">
 라이브러리 호출
 &lt;a class="anchor" href="#%eb%9d%bc%ec%9d%b4%eb%b8%8c%eb%9f%ac%eb%a6%ac-%ed%98%b8%ec%b6%9c">#&lt;/a>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torchvision
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch.nn &lt;span style="color:#66d9ef">as&lt;/span> nn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> torch.optim &lt;span style="color:#66d9ef">as&lt;/span> optim
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> torchvision &lt;span style="color:#f92672">import&lt;/span> transforms
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy &lt;span style="color:#66d9ef">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> ssl
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ssl&lt;span style="color:#f92672">.&lt;/span>_create_default_https_context &lt;span style="color:#f92672">=&lt;/span> ssl&lt;span style="color:#f92672">.&lt;/span>_create_unverified_context
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="data-augmentation">
 Data Augmentation
 &lt;a class="anchor" href="#data-augmentation">#&lt;/a>
&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Augmentation&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_transfrom &lt;span style="color:#f92672">=&lt;/span> transforms&lt;span style="color:#f92672">.&lt;/span>Compose([
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>Resize((&lt;span style="color:#ae81ff">227&lt;/span>, &lt;span style="color:#ae81ff">227&lt;/span>)), 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>ToTensor(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_transform &lt;span style="color:#f92672">=&lt;/span> transforms&lt;span style="color:#f92672">.&lt;/span>Compose([
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>Resize((&lt;span style="color:#ae81ff">227&lt;/span>, &lt;span style="color:#ae81ff">227&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>RandomHorizontalFlip(&lt;span style="color:#ae81ff">0.5&lt;/span>), 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> transforms&lt;span style="color:#f92672">.&lt;/span>ToTensor(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>아래 데이터에서 나오겠지만, ImageNet 데이터는 너무 커서 CIFAR-100 데이터로 대체했다. 그래서 ImageNet과는 다르게 CIFAR-100은 32×32라 227×227로 resize 해주는 과정이 필요했다. (여기서부터 학습시킬 의지를 잃었다.) 그렇기 때문에 이미지에서 224×224 패치를 추출하는 방법은 사용하지 못했다.&lt;br>
그리고, RGB 뭐 방법은 이해를 못해서 구현을 못했다. 나중에 해봐야지..&lt;/p></description></item><item><title>DQN 논문</title><link>https://yera10.github.io/docs/mystudy/deep-learning-study/paper_dqn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/paper_dqn/</guid><description>&lt;h1 id="playing-atari-with-deep-reinforcement-learning">
 Playing Atari with Deep Reinforcement Learning
 &lt;a class="anchor" href="#playing-atari-with-deep-reinforcement-learning">#&lt;/a>
&lt;/h1>
&lt;p>&lt;a href="https://arxiv.org/abs/1312.5602">paper&lt;/a> (2013)&lt;/p>
&lt;h2 id="abstract">
 Abstract
 &lt;a class="anchor" href="#abstract">#&lt;/a>
&lt;/h2>
&lt;p>We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning.&lt;/p>
&lt;p>The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. &lt;br>
모델은 Q-learing으로 변형 학습된 CNN인데,
raw pixel을 입력으로 받고, 미래 보상을 추정하는 value function 이다.&lt;/p></description></item><item><title>AI, Math</title><link>https://yera10.github.io/docs/mystudy/deep-learning-study/dl_aimath/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/dl_aimath/</guid><description>&lt;h1 id="ai와-math">
 AI와 Math
 &lt;a class="anchor" href="#ai%ec%99%80-math">#&lt;/a>
&lt;/h1>
&lt;h3 id="나중에-시간이-있다면-볼만한-책과-강의">
 나중에 시간이 있다면 볼만한 책과 강의
 &lt;a class="anchor" href="#%eb%82%98%ec%a4%91%ec%97%90-%ec%8b%9c%ea%b0%84%ec%9d%b4-%ec%9e%88%eb%8b%a4%eb%a9%b4-%eb%b3%bc%eb%a7%8c%ed%95%9c-%ec%b1%85%ea%b3%bc-%ea%b0%95%ec%9d%98">#&lt;/a>
&lt;/h3>
&lt;ul>
&lt;li>책: &lt;a href="https://mml-book.github.io/">Mathematics for Machine Learning&lt;/a>&lt;/li>
&lt;li>책: &lt;a href="https://ko.d2l.ai/index.html">Dive into Deep Learning&lt;/a>&lt;/li>
&lt;li>수학강의: &lt;a href="https://ko.khanacademy.org/">칸아카데미&lt;/a>&lt;/li>
&lt;li>수학영상: &lt;a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw">3Blue1Brown(Youtube)&lt;/a>&lt;/li>
&lt;li>수학강의: &lt;a href="https://www.coursera.org/specializations/mathematics-machine-learning">Mathematics for Machine Learning&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://www.kmooc.kr/courses/course-v1:SKKUk&amp;#43;SKKU_45&amp;#43;2021_T1/about">인공지능을 위한 기초수학 입문(KMOOC)&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>PyTorch</title><link>https://yera10.github.io/docs/mystudy/deep-learning-study/dl_pytorch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/dl_pytorch/</guid><description>&lt;h3 id="pytorch-further-reading">
 PyTorch Further Reading
 &lt;a class="anchor" href="#pytorch-further-reading">#&lt;/a>
&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software">딥러닝 프레임워크 비교&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://wikidocs.net/book/2788">PyTorch로 시작하는 딥러닝 입문&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/tutorials/">PyTorch 튜토리얼&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples">PyTorch Autograd 튜토리얼&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial">Autograd 튜토리얼&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_autograd.html">Tensor와 Autograd 튜토리얼&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817">PyTorch로 Linear Regression 하기&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/dair-ai/implementing-a-logistic-regression-model-from-scratch-with-pytorch-24ea062cd856">Pytorch로 Logistic Regression 하기&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">DDP(Distributed Data Parallel) 튜토리얼&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="pytorch-template">
 Pytorch Template
 &lt;a class="anchor" href="#pytorch-template">#&lt;/a>
&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://github.com/victoresque/pytorch-template">https://github.com/victoresque/pytorch-template&lt;/a>&lt;/li>
&lt;li>Pytorch Template2 &lt;a href="https://github.com/FrancescoSaverioZuppichini/PyTorch-Deep-Learning-Template">https://github.com/FrancescoSaverioZuppichini/PyTorch-Deep-Learning-Template&lt;/a>&lt;/li>
&lt;li>Pytorch Lightning Template &lt;a href="https://github.com/Lightning-AI/deep-learning-project-template">https://github.com/Lightning-AI/deep-learning-project-template&lt;/a>&lt;/li>
&lt;li>Pytorch Lightning &lt;a href="https://www.pytorchlightning.ai/">https://www.pytorchlightning.ai/&lt;/a>&lt;/li>
&lt;li>Pytorch Lightning + NNI Boilerplate &lt;a href="https://github.com/davinnovation/pytorch-boilerplate">https://github.com/davinnovation/pytorch-boilerplate&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="colab과-ngrok-사용하기">
 colab과 ngrok 사용하기
 &lt;a class="anchor" href="#colab%ea%b3%bc-ngrok-%ec%82%ac%ec%9a%a9%ed%95%98%ea%b8%b0">#&lt;/a>
&lt;/h3>
&lt;ul>
&lt;li>local에서 colab cloud에 접근할 수 있는 tool?
colab이라는 게 결국 컴퓨터잖아? 여기에 접속할 수 있음. 원격지에 있는 컴퓨터에 !
우리가 컴퓨터 환경을 쓰듯이 똑같이 쓸 수 있는데 , 그걸지원해주는 도구 중 하나가 ngrok&lt;/li>
&lt;li>가입 후, 토큰 필요&lt;/li>
&lt;li>코랩(클라우드)에 colab-ssh 설치 필요
( 내 원격 컴퓨터(colab)에 외부에서 ssh로 접속할 수있는 프로그램을 설치 )
외부에서 ssh로 접근할 수 있도록 해줌.&lt;/li>
&lt;li>vscode에서 확장프로그램으로 remote - ssh 설치 필요&lt;/li>
&lt;/ul>
&lt;h3 id="공부할-것">
 공부할 것
 &lt;a class="anchor" href="#%ea%b3%b5%eb%b6%80%ed%95%a0-%ea%b2%83">#&lt;/a>
&lt;/h3>
&lt;ul>
&lt;li>튜닝 도구 Ray 사용법 익히기 (딥러닝 뿐만 아니라 ML 알고리즘, RL, python의 일반적인 병렬처리에서도 많이 사용)&lt;/li>
&lt;/ul></description></item><item><title>Output Size 계산</title><link>https://yera10.github.io/docs/mystudy/deep-learning-study/outputsize/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/outputsize/</guid><description>&lt;h1 id="convolutional-layer에서-출력-크기-계산하기">
 Convolutional Layer에서 출력 크기 계산하기
 &lt;a class="anchor" href="#convolutional-layer%ec%97%90%ec%84%9c-%ec%b6%9c%eb%a0%a5-%ed%81%ac%ea%b8%b0-%ea%b3%84%ec%82%b0%ed%95%98%ea%b8%b0">#&lt;/a>
&lt;/h1>
&lt;p>
&lt;link rel="stylesheet" href="https://yera10.github.io/katex/katex.min.css" />
&lt;script defer src="https://yera10.github.io/katex/katex.min.js">&lt;/script>
&lt;script defer src="https://yera10.github.io/katex/auto-render.min.js" onload="renderMathInElement(document.body);">&lt;/script>&lt;span>
 \[OH = \frac{H &amp;#43; 2P - FH}{S} &amp;#43; 1\]
&lt;/span>

&lt;span>
 \[OW = \frac{W &amp;#43; 2P - FW}{S}&amp;#43;1\]
&lt;/span>
&lt;/p>
&lt;ul>
&lt;li>OH, OW: 출력될 피처맵의 높이(height), 너비(width)&lt;/li>
&lt;li>H, W: 입력되는 이미지(또는 피처맵)의 높이(height), 너비(width)&lt;/li>
&lt;li>P: 패딩 사이즈&lt;/li>
&lt;li>FH, FW: 필터(커널)의 높이, 너비&lt;/li>
&lt;li>S: stride 사이즈&lt;/li>
&lt;/ul></description></item><item><title/><link>https://yera10.github.io/docs/mystudy/deep-learning-study/paper_lora/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/paper_lora/</guid><description>&lt;h1 id="lora-low-rank-adaptation-of-large-language-models">
 LoRA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS
 &lt;a class="anchor" href="#lora-low-rank-adaptation-of-large-language-models">#&lt;/a>
&lt;/h1>
&lt;blockquote>
&lt;p>&lt;a href="https://arxiv.org/pdf/2106.09685.pdf">paper&lt;/a>&lt;br>
&lt;a href="https://velog.io/@kameleon43/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-LORA-LOW-RANK-ADAPTATION-OF-LARGE-LANGUAGE-MODELS">참고&lt;/a>&lt;br>
&lt;a href="https://youtu.be/BJqwmDpa0wM?si=PvFFUPCHEBKeZq6H">유튜브 딥러닝논문읽기모임&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>파라미터 사이즈가 점점 커짐에 따른 Parameter Efficient Tuning 기법 중 하나&lt;/li>
&lt;li>downstream task&lt;/li>
&lt;li>fine-tuning 하는 과제&lt;/li>
&lt;li>모든 dense layer에 적용 가능&lt;/li>
&lt;li>효율적인 튜닝 달성&lt;/li>
&lt;/ul></description></item><item><title/><link>https://yera10.github.io/docs/mystudy/deep-learning-study/readme/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://yera10.github.io/docs/mystudy/deep-learning-study/readme/</guid><description>&lt;h1 id="dl">
 DL
 &lt;a class="anchor" href="#dl">#&lt;/a>
&lt;/h1>
&lt;p>Deep Learning 공부 기록 노트&lt;/p></description></item></channel></rss>