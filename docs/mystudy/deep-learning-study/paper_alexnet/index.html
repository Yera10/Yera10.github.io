<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  ImageNet Classification with Deep Convolutional Neural Networks
  #

paper

  Abstract
  #


ImageNet LSVRC-2010 (1,200,000장의 고해상도 이미지들)를 1000개의 클래스로 분류하는 CNN 모델
기존 SOTA보다 향상된 성능
6천만개의 파라미터, 65만개의 뉴런으로 이루어져있고, 5개의 Conv-layer와 3개의 FC-layer로 구성되어있다. (최종은 1000-way softmax)
빠르게 훈련시키기 위해 비포화 뉴런과 GPU 구현을 사용
FC-layer에서 오버피팅을 줄이기 위해 dropout 방법 적용
또한, Alexnet의 변형은 ILSVRC-2012에서 오류율 15.3%로 우승한 딥러닝 신경망 아키텍처이다.


  Introduction
  #


이 논문의 기여도

ImageNet데이터로 훈련한 CNN모델로 이 데이터셋에 대한 최고의 성능에 달성
2D conv에 최적화된 GPU 구현과 공개
성능을 향상시키고 훈련시간을 단축시키는 몇 가지 특징들이 있다 (Section 3)
오버피팅을 방지하는 몇 가지 기술들 (Section 4)


이당시 2개의 GTX 580 3GB GPUs로 훈련했을 때, 5~6일 소요됐다.


  Dataset: ImageNet
  #


약 22,000개의 카테고리로 이루어진 1천5백만개 이상의 라벨이 있는 고해상도 이미지이다.
top-5 error rate는 뭐지?
ImageNet은 다양한 해상도의 이미지로 구성되어있지만, AlexNet은 일정한 차원으로 입력해야 하므로, 256x256 고정으로 다운샘플해야 한다.
직사각형 이미지에 대해서, 짧은 변을 256으로 resize하고, 중앙 256x256을 잘라내는 작업을 했음.


  Architecture
  #

AlexNet의 아키텍처는 아래와 같이 Conv layer 5 계층 + FC layer 3 계층으로 구성되어 있고, 4가지 특징을 가지고 있다."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yera10.github.io/docs/mystudy/deep-learning-study/paper_alexnet/"><meta property="og:site_name" content="이세상의 모든 노트"><meta property="og:title" content="AlexNet 논문"><meta property="og:description" content=" ImageNet Classification with Deep Convolutional Neural Networks # paper
Abstract # ImageNet LSVRC-2010 (1,200,000장의 고해상도 이미지들)를 1000개의 클래스로 분류하는 CNN 모델 기존 SOTA보다 향상된 성능 6천만개의 파라미터, 65만개의 뉴런으로 이루어져있고, 5개의 Conv-layer와 3개의 FC-layer로 구성되어있다. (최종은 1000-way softmax) 빠르게 훈련시키기 위해 비포화 뉴런과 GPU 구현을 사용 FC-layer에서 오버피팅을 줄이기 위해 dropout 방법 적용 또한, Alexnet의 변형은 ILSVRC-2012에서 오류율 15.3%로 우승한 딥러닝 신경망 아키텍처이다. Introduction # 이 논문의 기여도 ImageNet데이터로 훈련한 CNN모델로 이 데이터셋에 대한 최고의 성능에 달성 2D conv에 최적화된 GPU 구현과 공개 성능을 향상시키고 훈련시간을 단축시키는 몇 가지 특징들이 있다 (Section 3) 오버피팅을 방지하는 몇 가지 기술들 (Section 4) 이당시 2개의 GTX 580 3GB GPUs로 훈련했을 때, 5~6일 소요됐다. Dataset: ImageNet # 약 22,000개의 카테고리로 이루어진 1천5백만개 이상의 라벨이 있는 고해상도 이미지이다. top-5 error rate는 뭐지? ImageNet은 다양한 해상도의 이미지로 구성되어있지만, AlexNet은 일정한 차원으로 입력해야 하므로, 256x256 고정으로 다운샘플해야 한다. 직사각형 이미지에 대해서, 짧은 변을 256으로 resize하고, 중앙 256x256을 잘라내는 작업을 했음. Architecture # AlexNet의 아키텍처는 아래와 같이 Conv layer 5 계층 + FC layer 3 계층으로 구성되어 있고, 4가지 특징을 가지고 있다."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><title>AlexNet 논문 | 이세상의 모든 노트</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=stylesheet href=/book.min.33a48f5432973b8ff9a82679d9e45d67f2c15d4399bd2829269455cfe390b5e8.css integrity="sha256-M6SPVDKXO4/5qCZ52eRdZ/LBXUOZvSgpJpRVz+OQteg=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.443e0f646fc718b3bd77d0ebaf54a73fa183d3ce8de9d7340919fd780949b241.js integrity="sha256-RD4PZG/HGLO9d9Drr1SnP6GD086N6dc0CRn9eAlJskE=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-B1LML6H5K9"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-B1LML6H5K9")}</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>이세상의 모든 노트</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><input type=checkbox id=section-4408670ce68d5480e0ac700006be2fbe class=toggle checked>
<label for=section-4408670ce68d5480e0ac700006be2fbe class="flex justify-between"><a href=/docs/mystudy/>My Study</a></label><ul><li><input type=checkbox id=section-43609ff8ade5f49a9a42f6c75dfa8b7c class=toggle>
<label for=section-43609ff8ade5f49a9a42f6c75dfa8b7c class="flex justify-between"><a href=/docs/mystudy/algorithm-note/>알고리즘</a></label><ul><li><input type=checkbox id=section-87f5a5aba3a2eaef9e324cd61b28b682 class=toggle>
<label for=section-87f5a5aba3a2eaef9e324cd61b28b682 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/>Part 2</a></label><ul><li><input type=checkbox id=section-9ecde276efb9d73a10e822395ea24222 class=toggle>
<label for=section-9ecde276efb9d73a10e822395ea24222 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/>3. 그리디 알고리즘</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/1%EC%9D%B4%EB%90%A0%EB%95%8C%EA%B9%8C%EC%A7%80/>1이될때까지</a></li><li><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/%EC%88%AB%EC%9E%90%EC%B9%B4%EB%93%9C%EA%B2%8C%EC%9E%84/>숫자카드게임</a></li><li><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/%ED%81%B0%EC%88%98%EC%9D%98%EB%B2%95%EC%B9%99/>큰수의법칙</a></li></ul></li><li><input type=checkbox id=section-d6c984057099e052e66a4f1aa50e7f0c class=toggle>
<label for=section-d6c984057099e052e66a4f1aa50e7f0c class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/>4. 구현</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EA%B2%8C%EC%9E%84-%EA%B0%9C%EB%B0%9C/>게임 개발</a></li><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EC%83%81%ED%95%98%EC%A2%8C%EC%9A%B0/>상하좌우</a></li><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EC%8B%9C%EA%B0%81/>시각</a></li><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EC%99%95%EC%8B%A4%EC%9D%98%EB%82%98%EC%9D%B4%ED%8A%B8/>왕실의나이트</a></li></ul></li><li><input type=checkbox id=section-32c1b3fcaa327485a5a7afbcc8ea04d2 class=toggle>
<label for=section-32c1b3fcaa327485a5a7afbcc8ea04d2 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/>5. DFS & BFS</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/%EB%AF%B8%EB%A1%9C%ED%83%88%EC%B6%9C/>미로탈출</a></li><li><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/%EC%9D%8C%EB%A3%8C%EC%88%98-%EC%96%BC%EB%A0%A4-%EB%A8%B9%EA%B8%B0/>음료수 얼려 먹기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/datastructure/>자료구조 기초</a></li></ul></li><li><input type=checkbox id=section-ec2ec8f1f45d90b15ad9249032dc4793 class=toggle>
<label for=section-ec2ec8f1f45d90b15ad9249032dc4793 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/>6. 정렬</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%84%B1%EC%A0%81%EC%9D%B4%EB%82%AE%EC%9D%80%EC%88%9C%EC%84%9C%EB%A1%9C/>성적이낮은순서로</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%9C%84%EC%97%90%EC%84%9C%EC%95%84%EB%9E%98%EB%A1%9C/>위에서아래로</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EA%B3%84%EC%88%98%EC%A0%95%EB%A0%AC/>계수정렬</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%82%BD%EC%9E%85%EC%A0%95%EB%A0%AC/>삽입정렬</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%84%A0%ED%83%9D%EC%A0%95%EB%A0%AC/>선택정렬</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%ED%80%B5%EC%A0%95%EB%A0%AC/>퀵정렬</a></li></ul></li><li><input type=checkbox id=section-4118e2eceb3f1bb89e7573c149cbccd8 class=toggle>
<label for=section-4118e2eceb3f1bb89e7573c149cbccd8 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/>7. 이진탐색</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/%EB%96%A1%EB%B3%B6%EC%9D%B4%EB%96%A1%EB%A7%8C%EB%93%A4%EA%B8%B0/>떡볶이떡만들기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/%EB%B6%80%ED%92%88%EC%B0%BE%EA%B8%B0/>부품찾기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/%EC%A7%95%EA%B2%80%EB%8B%A4%EB%A6%AC%EA%B1%B4%EB%84%88%EA%B8%B0/>징검다리건너기</a></li></ul></li><li><input type=checkbox id=section-0a6b47a1b1b81880d41ff66826f8e9d7 class=toggle>
<label for=section-0a6b47a1b1b81880d41ff66826f8e9d7 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/>8. DP</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/1%EB%A1%9C%EB%A7%8C%EB%93%A4%EA%B8%B0/>1로만들기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EA%B0%9C%EB%AF%B8%EC%A0%84%EC%82%AC/>개미전사</a></li><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%B0%94%EB%8B%A5%EA%B3%B5%EC%82%AC/>바닥공사</a></li><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%ED%9A%A8%EC%9C%A8%EC%A0%81%EC%9D%B8%ED%99%94%ED%8F%90%EA%B5%AC%EC%84%B1/>효율적인화폐구성</a></li></ul></li><li><input type=checkbox id=section-1662a2a656f5d3d320218332170be07a class=toggle>
<label for=section-1662a2a656f5d3d320218332170be07a class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/9_%EC%B5%9C%EB%8B%A8%EA%B2%BD%EB%A1%9C/>9. 최단경로</a></label><ul></ul></li></ul></li><li><input type=checkbox id=section-90ac3913cacd642470f02c4e44c235cb class=toggle>
<label for=section-90ac3913cacd642470f02c4e44c235cb class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part3/>Part 3</a></label><ul><li><input type=checkbox id=section-bf3c756a96c759cc7852b57440790b7f class=toggle>
<label for=section-bf3c756a96c759cc7852b57440790b7f class="flex justify-between"><a role=button>그리디 알고리즘</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EA%B3%B1%ED%95%98%EA%B8%B0-%ED%98%B9%EC%9D%80-%EB%8D%94%ED%95%98%EA%B8%B0/>곱하기 혹은 더하기</a></li><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EB%A7%8C%EB%93%A4%EC%88%98%EC%97%86%EB%8A%94%EA%B8%88%EC%95%A1/>만들수없는금액</a></li><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EB%AA%A8%ED%97%98%EA%B0%80%EA%B8%B8%EB%93%9C/>모험가길드</a></li><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EB%B3%BC%EB%A7%81%EA%B3%B5%EA%B3%A0%EB%A5%B4%EA%B8%B0/>볼링공고르기</a></li></ul></li></ul></li><li><a href=/docs/mystudy/algorithm-note/data_structure/>데이터 구조</a></li><li><a href=/docs/mystudy/algorithm-note/prime_number_code/>소수 관련 코드</a></li></ul></li><li><input type=checkbox id=section-472e96a9c612ee135e9f631f838b4095 class=toggle checked>
<label for=section-472e96a9c612ee135e9f631f838b4095 class="flex justify-between"><a href=/docs/mystudy/deep-learning-study/>딥러닝</a></label><ul><li><a href=/docs/mystudy/deep-learning-study/historical_review/>Historical Review</a></li><li><a href=/docs/mystudy/deep-learning-study/paper_alexnet/ class=active>AlexNet 논문</a></li><li><a href=/docs/mystudy/deep-learning-study/alexnet-in-pytorch/>AlexNet 구현 (Pytorch)</a></li><li><a href=/docs/mystudy/deep-learning-study/paper_dqn/>DQN 논문</a></li><li><a href=/docs/mystudy/deep-learning-study/dl_aimath/>AI, Math</a></li><li><a href=/docs/mystudy/deep-learning-study/dl_pytorch/>PyTorch</a></li><li><a href=/docs/mystudy/deep-learning-study/outputsize/>Output Size 계산</a></li><li><a href=/docs/mystudy/deep-learning-study/paper_lora/>Paper Lo Ra</a></li></ul></li><li><input type=checkbox id=section-f3798126b0dbeea9f1da219c60bc2374 class=toggle>
<label for=section-f3798126b0dbeea9f1da219c60bc2374 class="flex justify-between"><a href=/docs/mystudy/basic/>어쩌다 기초</a></label><ul><li><input type=checkbox id=section-a9c56ccf549539a810b33dfe2bd607ee class=toggle>
<label for=section-a9c56ccf549539a810b33dfe2bd607ee class="flex justify-between"><a href=/docs/mystudy/basic/python/>파이썬 문법</a></label></li></ul></li><li><input type=checkbox id=section-d0422ed221db5f77315362ccbc507475 class=toggle>
<label for=section-d0422ed221db5f77315362ccbc507475 class="flex justify-between"><a href=/docs/mystudy/hugo-blog/>Hugo로 github 블로그 만들기</a></label><ul><li><a href=/docs/mystudy/hugo-blog/1_%EC%84%A4%EC%B9%98/>셋팅 및 시작</a></li><li><a href=/docs/mystudy/hugo-blog/2_%EC%BB%A8%ED%85%90%EC%B8%A0%EC%97%B0%EA%B2%B0/>컨텐츠 연결</a></li><li><a href=/docs/mystudy/hugo-blog/3_%EC%9E%90%EB%8F%99%EC%97%85%EB%A1%9C%EB%93%9C/>자동 업로드</a></li></ul></li><li><input type=checkbox id=section-105c083095a4b56a13d572c56ababc26 class=toggle>
<label for=section-105c083095a4b56a13d572c56ababc26 class="flex justify-between"><a href=/docs/mystudy/coin-bot/>비트코인 자동매매 봇 만들기</a></label><ul><li><input type=checkbox id=section-4eef4ab57400105b07f8ddae1c891a6e class=toggle>
<label for=section-4eef4ab57400105b07f8ddae1c891a6e class="flex justify-between"><a href=/docs/mystudy/coin-bot/1_ccxt_api/>ccxt 라이브러리 사용</a></label></li><li><input type=checkbox id=section-66c43a7d75e7b97e4657392a8f77e902 class=toggle>
<label for=section-66c43a7d75e7b97e4657392a8f77e902 class="flex justify-between"><a href=/docs/mystudy/coin-bot/2_ccxt_websocket/>ccxt 웹소켓 사용</a></label></li></ul></li></ul></li><li class=book-section-flat><a href=/docs/memo/>메모장</a><ul><li><input type=checkbox id=section-dbf12aea4ba6ece0bc58517be081ff61 class=toggle>
<label for=section-dbf12aea4ba6ece0bc58517be081ff61 class="flex justify-between"><a href=/docs/memo/pytorch-study/>Pytorch</a></label><ul><li><a href=/docs/memo/pytorch-study/nn/>Nn</a></li><li><input type=checkbox id=section-d05407db8bfeedc9a29e39a783a69ac5 class=toggle>
<label for=section-d05407db8bfeedc9a29e39a783a69ac5 class="flex justify-between"><a href=/docs/memo/pytorch-study/dataset_module/>파이토치 데이터 모듈</a></label></li><li><input type=checkbox id=section-860b30dc364c1b43f944597b2d7cc950 class=toggle>
<label for=section-860b30dc364c1b43f944597b2d7cc950 class="flex justify-between"><a href=/docs/memo/pytorch-study/tensor/>파이토치 텐서?</a></label></li></ul></li><li><input type=checkbox id=section-617c0180a9bd5e684defbea9760a7725 class=toggle>
<label for=section-617c0180a9bd5e684defbea9760a7725 class="flex justify-between"><a href=/docs/memo/omg-error/>오마이갓 에러극복</a></label><ul><li><input type=checkbox id=section-1f707617003fe56304181dabf494e64c class=toggle>
<label for=section-1f707617003fe56304181dabf494e64c class="flex justify-between"><a href=/docs/memo/omg-error/poetry_venv_broken/>poetry 가상환경에 jupyter 설치 안됨</a></label></li></ul></li><li><input type=checkbox id=section-73671f80b377e01c565aa90aa7ee004a class=toggle>
<label for=section-73671f80b377e01c565aa90aa7ee004a class="flex justify-between"><a href=/docs/memo/commands/>자주 쓰는 명령어들</a></label><ul><li><input type=checkbox id=section-e603ea93b4c5641d8f935bf5a00859b8 class=toggle>
<label for=section-e603ea93b4c5641d8f935bf5a00859b8 class="flex justify-between"><a href=/docs/memo/commands/conda/>Conda</a></label><ul><li><a href=/docs/memo/commands/conda/virtual_env/>가상환경 관련</a></li></ul></li><li><input type=checkbox id=section-af0bdbd2a00e3e0b212a55987223ffc8 class=toggle>
<label for=section-af0bdbd2a00e3e0b212a55987223ffc8 class="flex justify-between"><a href=/docs/memo/commands/etc/>Etc</a></label><ul><li><a href=/docs/memo/commands/etc/docker/>Docker</a></li><li><a href=/docs/memo/commands/etc/python-parameter/>python 실행파일 인자값 받기</a></li><li><a href=/docs/memo/commands/etc/python-venv/>python3 venv 사용법</a></li><li><a href=/docs/memo/commands/etc/python-server/>python3 서버열기</a></li><li><a href=/docs/memo/commands/etc/vscode_shortcuts/>VSCode 단축키</a></li><li><a href=/docs/memo/commands/etc/terminal_theme/>터미널 테마</a></li></ul></li><li><input type=checkbox id=section-45cef228deb80bf75e3df458f39dc21a class=toggle>
<label for=section-45cef228deb80bf75e3df458f39dc21a class="flex justify-between"><a href=/docs/memo/commands/linux/>Linux</a></label><ul><li><a href=/docs/memo/commands/linux/gpu/>GPU 관련</a></li><li><a href=/docs/memo/commands/linux/screen/>Ubuntu Screen 명령어</a></li><li><a href=/docs/memo/commands/linux/background/>백그라운드 관련</a></li><li><a href=/docs/memo/commands/linux/zip_tar_gz/>압축 관련</a></li><li><a href=/docs/memo/commands/linux/file_dir/>파일 생성/이동/복사/삭제</a></li></ul></li><li><input type=checkbox id=section-8c56b6f03dacfd96ad3b5d449acaea30 class=toggle>
<label for=section-8c56b6f03dacfd96ad3b5d449acaea30 class="flex justify-between"><a href=/docs/memo/commands/poetry/>Poetry</a></label><ul><li><a href=/docs/memo/commands/poetry/poetry_start/>Poetry 시작하기</a></li><li><a href=/docs/memo/commands/poetry/virtual_env/>가상환경 관련</a></li><li><a href=/docs/memo/commands/poetry/export/>내보내기 (requirements.txt)</a></li><li><a href=/docs/memo/commands/poetry/dependency/>의존성 관련</a></li></ul></li><li><input type=checkbox id=section-d62e43e08089551fa5c3188ab2ea83ba class=toggle>
<label for=section-d62e43e08089551fa5c3188ab2ea83ba class="flex justify-between"><a href=/docs/memo/commands/git/>Git 관련</a></label><ul><li><a href=/docs/memo/commands/git/clone/>clone 관련</a></li><li><a href=/docs/memo/commands/git/cancel/>commit 취소</a></li><li><a href=/docs/memo/commands/git/credential/>credential 관련</a></li><li><a href=/docs/memo/commands/git/submodule/>서브모듈 관련</a></li><li><a href=/docs/memo/commands/git/initial_setup/>초기설정 관련</a></li></ul></li></ul></li><li><input type=checkbox id=section-232998b4ddb91b0de578d4b83588e89e class=toggle>
<label for=section-232998b4ddb91b0de578d4b83588e89e class="flex justify-between"><a href=/docs/memo/freq-used-code/>자주 쓰는 코드들</a></label><ul><li><a href=/docs/memo/freq-used-code/histogram/>간단한 히스토그램 python</a></li><li><a href=/docs/memo/freq-used-code/warnings/>경고 무시 python</a></li><li><a href=/docs/memo/freq-used-code/time/>시간 측정 python</a></li><li><a href=/docs/memo/freq-used-code/pretty_print/>예쁘게 출력(pprint) python</a></li><li><a href=/docs/memo/freq-used-code/file_zip/>파일 압축 python</a></li><li><a href=/docs/memo/freq-used-code/file_open/>파일 읽기 python</a></li></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>AlexNet 논문</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#dataset-imagenet>Dataset: ImageNet</a></li><li><a href=#architecture>Architecture</a><ul><li><a href=#1-relu-비선형-활성화-함수>1. ReLU 비선형 활성화 함수</a></li><li><a href=#2-여러-gpu로-학습>2. 여러 GPU로 학습</a></li><li><a href=#3-lrn-local-response-normalization>3. LRN (Local Response Normalization)</a></li><li><a href=#4-overlapping-pooling>4. Overlapping Pooling</a></li></ul></li><li><a href=#reducing-overfitting>Reducing Overfitting</a><ul><li><a href=#1-data-augmentation>1. Data Augmentation</a></li><li><a href=#2-dropout>2. Dropout</a></li></ul></li><li><a href=#details-of-learning>Details of learning</a></li></ul></nav></aside></header><article class=markdown><h1 id=imagenet-classification-with-deep-convolutional-neural-networks>ImageNet Classification with Deep Convolutional Neural Networks
<a class=anchor href=#imagenet-classification-with-deep-convolutional-neural-networks>#</a></h1><p><a href=https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf>paper</a></p><h2 id=abstract>Abstract
<a class=anchor href=#abstract>#</a></h2><ul><li>ImageNet LSVRC-2010 (1,200,000장의 고해상도 이미지들)를 1000개의 클래스로 분류하는 CNN 모델</li><li>기존 SOTA보다 향상된 성능</li><li>6천만개의 파라미터, 65만개의 뉴런으로 이루어져있고, 5개의 Conv-layer와 3개의 FC-layer로 구성되어있다. (최종은 1000-way softmax)</li><li>빠르게 훈련시키기 위해 비포화 뉴런과 GPU 구현을 사용</li><li>FC-layer에서 오버피팅을 줄이기 위해 dropout 방법 적용</li><li>또한, Alexnet의 변형은 ILSVRC-2012에서 오류율 15.3%로 우승한 딥러닝 신경망 아키텍처이다.</li></ul><h2 id=introduction>Introduction
<a class=anchor href=#introduction>#</a></h2><ul><li>이 논문의 기여도<ul><li>ImageNet데이터로 훈련한 CNN모델로 이 데이터셋에 대한 최고의 성능에 달성</li><li>2D conv에 최적화된 GPU 구현과 공개</li><li>성능을 향상시키고 훈련시간을 단축시키는 몇 가지 특징들이 있다 (Section 3)</li><li>오버피팅을 방지하는 몇 가지 기술들 (Section 4)</li></ul></li><li>이당시 2개의 GTX 580 3GB GPUs로 훈련했을 때, 5~6일 소요됐다.</li></ul><h2 id=dataset-imagenet>Dataset: ImageNet
<a class=anchor href=#dataset-imagenet>#</a></h2><ul><li>약 22,000개의 카테고리로 이루어진 1천5백만개 이상의 라벨이 있는 고해상도 이미지이다.</li><li>top-5 error rate는 뭐지?</li><li>ImageNet은 다양한 해상도의 이미지로 구성되어있지만, AlexNet은 일정한 차원으로 입력해야 하므로, 256x256 고정으로 다운샘플해야 한다.</li><li>직사각형 이미지에 대해서, 짧은 변을 256으로 resize하고, 중앙 256x256을 잘라내는 작업을 했음.</li></ul><h2 id=architecture>Architecture
<a class=anchor href=#architecture>#</a></h2><p>AlexNet의 아키텍처는 아래와 같이 <strong>Conv layer 5 계층 + FC layer 3 계층</strong>으로 구성되어 있고, 4가지 특징을 가지고 있다.</p><p><img src="https://onedrive.live.com/embed?resid=6FDBBD3E0E61A2CF%2112906&amp;authkey=%21AMsJTNKuUuRVlEY" alt="alexnet architecture"></p><ul><li>마지막 FC-layer의 출력은 <strong>1000-way 소프트맥스</strong>로 입력되어 1000개의 클래스 라벨에 대한 분포값을 생성해낸다.</li><li>이 네트워크는 다항 로지스틱 회귀 목표를 최대화하는데, 이는 예측 분포 하에서 정확한 레이블의 로그 확률의 훈련 사례에 걸친 평균을 최대화하는 것과 같습니다. (??)</li><li>2,4,5번째 컨볼루션 레이어는 동일한 GPU에 상주하는 이전 레이어의 커널 맵에만 연결되어 있다.</li><li>세번째 컨볼루션 레이어는 두번째 컨볼루션 레이어의 모든 커널맵과 연결되어있다.</li><li>FC(fully-connected)레이어들은 이전 레이어의 모든 뉴런과 연결되어 있다.</li><li>LRN 레이어는 1,2번째 컨볼루션 레이어 다음에 적용됐다.</li><li>max-pooling은 1,2 번째 컨볼루션 레이어 다음과 5번째 컨볼루션 레이어 뒤에도 적용되었다.</li><li>ReLU 비선형 함수는 모든 레이어의 출력값에 적용되었다.</li><li>첫번째 컨볼루션 레이어는 11x11x3 크기의 커널 96개와 4 stride로 224x224x3 사이즈의 이미지를 필터링한다.</li><li>두번째 컨볼루션 레이어는 첫 레이어의 출력을 입력으로 받아 5x5x48 크기의 커널 256개로 필터링한다.</li><li>3,4,5번째 컨볼루션 레이어들은 풀링이나 정규화 없이 서로 연결된다.</li><li>세번째 컨볼루션 레이어에서는 3x3x256 크기의 커널 384개로 두번째 레이어의 출력과 연결시킨다.</li><li>네번째 컨볼루션 레이어는 3x3x192 크기의 커널 384개로 필터링한다.</li><li>다섯번째 컨볼루션 레이어는 3x3x192 크기의 커널 256개로 필터링해 13x13x256 크기를 출력한다.</li><li>FC-layer는 각각 4096개의 뉴런을 가지고 있다.</li></ul><h3 id=1-relu-비선형-활성화-함수>1. ReLU 비선형 활성화 함수
<a class=anchor href=#1-relu-%eb%b9%84%ec%84%a0%ed%98%95-%ed%99%9c%ec%84%b1%ed%99%94-%ed%95%a8%ec%88%98>#</a></h3><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><span>\[f(x) = max(0,\space x)\]</span><ul><li>활성화 함수로 표준은 <span>\( f(x) = tanh(x) \)
</span>또는 <span>\( f(x) = (1+e^{-x})^{-1} \)
</span>를 쓰는 것이다.</li><li>경사하강법의 측면에서, 포화 비선형성<em>saturating nonlinearities</em>은 비포화 비선형성<em>non-saturating nonlinearity</em> (<span>
\( f(x) = max(0,\space x) \)
</span>, ReLU)보다 느리다.</li><li>위 수식으로 비선형성을 가진 뉴런을 ReLU라고 한다. <em>Rectified Linear Units</em></li><li>ReLU를 사용한 Deep-CNN은 tanh를 사용한 똑같은 Deep-CNN보다 몇배는 빠르다.</li></ul><h3 id=2-여러-gpu로-학습>2. 여러 GPU로 학습
<a class=anchor href=#2-%ec%97%ac%eb%9f%ac-gpu%eb%a1%9c-%ed%95%99%ec%8a%b5>#</a></h3><ul><li>GTX 580 GPU 하나는 3GB 메모리밖에 없어, 학습할 수 있는 네트워크의 최대 크기가 제한된다.</li><li>120만개 훈련데이터는 1개의 GPU보다 훨씬 큰 네트워크에서 훈련시킬 수 있다(?)</li><li>그래서 2개의 GPU에 걸쳐 신경망을 분포시킴 (?)</li><li>현재 GPU는 크로스 GPU 병렬화에 특히 적합하다. 왜냐하면, 서로의 메모리를 호스트 시스템 메모리를 거치지 않고 직접 읽어들이고, 쓸 수 있기 때문이다.</li><li>여기서 사용하는 병렬화 방식은 각 GPU에 뉴런을 절반만 배치하며, GPU가 특정 계층에서만 통신한다는 추가 기술이 있다. 예를 들어, layer 3의 뉴런들은 input을 layer 2의 모든 커널 맵에서 가져오지만, layer 4는 input을 같은 GPU에 있는 layer 3의 커널 맵들에서만 가져온다.</li><li>연결 패턴을 선택하는 것은 교차 검증의 문제이지만, 이를 통해 계산량의 허용 가능한 부분이 될 때까지 통신량을 정확하게 조정할 수 있습니다</li><li>2개의 GPU로 학습시킨 신경망이 약간 더 빨리 끝났다.</li></ul><h3 id=3-lrn-local-response-normalization>3. LRN (Local Response Normalization)
<a class=anchor href=#3-lrn-local-response-normalization>#</a></h3><ul><li>ReLU는 포화 방지를 위해 input 정규화가 필요하지 않다는 장점이 있다.</li><li>훈련 샘플에서 ReLU에 양수가 입력되면 뉴런에서 학습이 이뤄진다.</li><li>로컬 정규화가 일반화에 도움이 된다는 것을 발견했다.</li></ul><span>\[b_{x,y}^i = a_{x,y}^i/ \Bigg( k + \alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+2/n)}(a_{x,y}^j)^2 \Bigg)^\beta\]</span><ul><li>N은 해당 layer의 총 커널 수</li><li>상수 <span>\(k, n, \alpha, \beta\)
</span>는 validation 데이터로 결정되는 하이퍼파라미터</li><li>특정 층에서 ReLU 비선형 함수를 적용한 후에 이 LRN 정규화를 적용했다.</li></ul><div class=book-expand><label><div class="book-expand-head flex justify-between"><span>ChatGPT가 알려준 LRN이란</span>
<span>▼</span></div><input type=checkbox class=hidden><div class="book-expand-content markdown-inner"><ul><li>정규화 기법 중 하나</li><li>LRN 은 활성화 맵 내의 각 위치에서 주변의 값들을 사용하여 정규화를 수행.</li><li>목적: 활성화 맵의 각 요소를 해당 위치에서 주변의 값들을 정규화함으로써, 네트워크의 일반화 성능을 향상시키기 위한 목적으로 도입되었습니다.</li><li>효과: LRN을 통해 활성화 값이 어떤 위치에서 다른 필터들의 활성화 값에 대해 정규화되므로, 더 강력한 활성화 패턴을 학습하고 일반화 성능을 향상시킬 수 있습니다.</li><li>AlexNet에서는 LRN가 합성곱 계층 뒤에 적용되었으며, 이로인해 전체 네트워크의 성능이 향상되었습니다.</li><li>LRN은 현재는 주로 사용되지 않는 표준 정규화 기법 중 하나이지만, AlexNet에서 처음 도입되어 성능 향상에 기여한 중요한 요소 중 하나였다.</li></ul></div></label></div><h3 id=4-overlapping-pooling>4. Overlapping Pooling
<a class=anchor href=#4-overlapping-pooling>#</a></h3><ul><li>CNN에서 pooling 계층은 이웃 뉴런 그룹의 출력을 요약한다.</li><li>전통적인 방법으로 풀링을 할 경우, 인접한 pooling 단위는 겹치지 않는다. 좀 더 정확히 말하면, 풀링 레이어는 풀링 단위의 그리드로 구성되고, z x z 크기의 인접한 부분을 요약한다.</li><li>이렇게 겹치도록 pooling을 하면 오버피팅 방지에도 약간 효과가 있다.</li></ul><h2 id=reducing-overfitting>Reducing Overfitting
<a class=anchor href=#reducing-overfitting>#</a></h2><p>오버피팅에 대항하는 주요방법 2가지를 소개합니다.</p><h3 id=1-data-augmentation>1. Data Augmentation
<a class=anchor href=#1-data-augmentation>#</a></h3><ul><li>과적합을 줄이는 가장 쉽고 일반적인 방법으로, 라벨 보존 변환으로 데이터를 인위적으로 증대시키는 것</li><li>두 가지 데이터 증강 방법이 있는데, 둘 다 매우 적은 계산으로 변환 이미지를 생성할 수 있어 변환 이미지를 디스크에 저장할 필요가 없다.</li><li>GPU가 이전 배치를 훈련하는 동안 CPU에서 이미지 변환을 하기 때문에 데이터 증강 기법은 사실상 계산적으로 비용이 거의 들지 않는다.</li><li>이미지 변환과 수평 반전으로 생성하는 방법 한가지.</li><li>테스트 할 때에는, 이미지의 네 모서리와 중앙에서 224x224 패치 5개를 추출하고, 수평 반전으로 총 10개의 패치를 생성한 뒤, 10개의 패치를 신경망에 흘려보내 소프트맥스 계층의 결과를 얻고, 그 결과를 평균화하여 예측한다.</li><li>RGB 픽셀 값에 대해 PCA를 수행하여 RGB 채널의 강도를 변경하는 증강방법 한가지.</li></ul><h3 id=2-dropout>2. Dropout
<a class=anchor href=#2-dropout>#</a></h3><ul><li>여러 모델의 예측결과를 결합하는 앙상블 기법은 아주 좋지만, 비용이 너무 많이 든다.</li><li>비용을 크게 들이지 않고 효율적으로 과적합을 방지하는 방법</li><li>0.5의 확률로 hidden 뉴런의 결과를 0으로 셋팅하는 것</li><li>드롭아웃된 뉴런들은 forward pass에 기여하지 않고, 역전파에 참여하지 않는다.</li><li>입력이 들어올 때마다 다른 구조의 신경망을 샘플링하지만, 모든 구조는 가중치를 공유한다.</li><li>어떤 뉴런이 특정 다른 뉴런에 의존할 수 없기 때문에 뉴런 간 복잡한 공생현상을 감소시킨다.</li><li>테스트 시에는 모든 뉴런을 사용하지만, 그 출력값에 0.5를 곱한다.</li><li>dropout은 FC-layer에서 사용되며, dropout이 없었다면 상당한 과적합이 일어났을 것이다.</li><li>dropout은 수렴하기까지 거의 2배의 iteration이 필요하다.</li></ul><h2 id=details-of-learning>Details of learning
<a class=anchor href=#details-of-learning>#</a></h2><ul><li>stochastic gradient descent 사용</li><li>128 batch size</li><li>momentum 0.9</li><li>weight decay 0.0005</li></ul><p>가중치 <span>\(w\)
</span>의 업데이트 룰은 다음과 같다.
<span>\[v_{i+1} := 0.9 \cdot v_i - 0.0005 \cdot \epsilon \cdot w_i - \epsilon \cdot \bigg&lt; \frac{\partial L}{\partial w} \Big|_{w_i} \bigg>_{D_i}\]</span></p><ul><li><span>\(i\)
</span>: iteration index</li><li><span>\(v\)
</span>: 모멘텀 변수 (?)</li><li><span>\(\epsilon\)
</span>: learning rate</li><li><span>\(\Big&lt; \frac{\partial L}{\partial w} \Big|_{w_i} \Big>_{D_i}\)
</span>: w_i에서 평가된 w 에 대한 목표 도함수의 i번째 배치 D_i에 대한 평균 (?)</li></ul><p> </p><ul><li>평균이 0, 표준편차가 0.01인 가우스 분포에서 각 layer의 가중치 초기화 함.</li><li>2,4,5번째 conv-layer와 FC-layer의 hidden-layer의 뉴런 바이어스를 모두 1로 초기화 함.</li><li>이 초기화 방법은 ReLU에 양수 입력을 함으로써 학습 초기 단계를 가속화 한다.</li><li>나머지 레이어의 뉴런 바이어스는 0으로 초기화</li><li>모든 계층에 대해 동일한 학습률을 사용했고, 훈련 중 수동으로 조정했다.</li><li>validation 에러율이 개선되지 않을 때, 학습률을 10으로 나누는 휴리스틱을 따름</li><li>학습률은 0.01에서 시작해 종료까지 3번 감소되었다</li><li>120만장의 이미지 훈련 데이터를 대략 90번의 사이클을 훈련했고, NVIDIA GTX 580 3GB GPU 두개를 이용하여 5~6일 걸렸다</li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#dataset-imagenet>Dataset: ImageNet</a></li><li><a href=#architecture>Architecture</a><ul><li><a href=#1-relu-비선형-활성화-함수>1. ReLU 비선형 활성화 함수</a></li><li><a href=#2-여러-gpu로-학습>2. 여러 GPU로 학습</a></li><li><a href=#3-lrn-local-response-normalization>3. LRN (Local Response Normalization)</a></li><li><a href=#4-overlapping-pooling>4. Overlapping Pooling</a></li></ul></li><li><a href=#reducing-overfitting>Reducing Overfitting</a><ul><li><a href=#1-data-augmentation>1. Data Augmentation</a></li><li><a href=#2-dropout>2. Dropout</a></li></ul></li><li><a href=#details-of-learning>Details of learning</a></li></ul></nav></div></aside></main></body></html>