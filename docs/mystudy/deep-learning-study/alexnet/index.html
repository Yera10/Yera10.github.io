<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="AlexNet # 논문 요약 정리 논문
Abstract # ImageNet LSVRC-2010 (1,200,000장의 고해상도 이미지들)를 1000개의 클래스로 분류하는 CNN 모델 기존 SOTA보다 향상된 성능 6천만개의 파라미터, 65만개의 뉴런으로 이루어져있고, 5개의 Conv-layer와 3개의 FC-layer로 구성되어있다. (최종은 1000-way softmax) 빠르게 훈련시키기 위해 비포화 뉴런과 GPU 구현을 사용 FC-layer에서 오버피팅을 줄이기 위해 dropout 방법 적용 또한, Alexnet의 변형은 ILSVRC-2012에서 오류율 15.3%로 우승한 딥러닝 신경망 아키텍처이다. Introduction # 이 논문의 기여도 ImageNet데이터로 훈련한 CNN모델로 이 데이터셋에 대한 최고의 성능에 달성 2D conv에 최적화된 GPU 구현과 공개 성능을 향상시키고 훈련시간을 단축시키는 몇 가지 특징들이 있다 (Section 3) 오버피팅을 방지하는 몇 가지 기술들 (Section 4) 이당시 2개의 GTX 580 3GB GPUs로 훈련했을 때, 5~6일 소요됐다."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:title" content><meta property="og:description" content="AlexNet # 논문 요약 정리 논문
Abstract # ImageNet LSVRC-2010 (1,200,000장의 고해상도 이미지들)를 1000개의 클래스로 분류하는 CNN 모델 기존 SOTA보다 향상된 성능 6천만개의 파라미터, 65만개의 뉴런으로 이루어져있고, 5개의 Conv-layer와 3개의 FC-layer로 구성되어있다. (최종은 1000-way softmax) 빠르게 훈련시키기 위해 비포화 뉴런과 GPU 구현을 사용 FC-layer에서 오버피팅을 줄이기 위해 dropout 방법 적용 또한, Alexnet의 변형은 ILSVRC-2012에서 오류율 15.3%로 우승한 딥러닝 신경망 아키텍처이다. Introduction # 이 논문의 기여도 ImageNet데이터로 훈련한 CNN모델로 이 데이터셋에 대한 최고의 성능에 달성 2D conv에 최적화된 GPU 구현과 공개 성능을 향상시키고 훈련시간을 단축시키는 몇 가지 특징들이 있다 (Section 3) 오버피팅을 방지하는 몇 가지 기술들 (Section 4) 이당시 2개의 GTX 580 3GB GPUs로 훈련했을 때, 5~6일 소요됐다."><meta property="og:type" content="article"><meta property="og:url" content="https://yera10.github.io/docs/mystudy/deep-learning-study/alexnet/"><meta property="article:section" content="docs"><title>Alexnet | 이세상의 모든 노트</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=stylesheet href=/book.min.33a48f5432973b8ff9a82679d9e45d67f2c15d4399bd2829269455cfe390b5e8.css integrity="sha256-M6SPVDKXO4/5qCZ52eRdZ/LBXUOZvSgpJpRVz+OQteg=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.6dd4596050fd297f3849af4813f3dc7aa9dd8866d20db8951ccfe25fb2530256.js integrity="sha256-bdRZYFD9KX84Sa9IE/PceqndiGbSDbiVHM/iX7JTAlY=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-B1LML6H5K9"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-B1LML6H5K9",{anonymize_ip:!1})}</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>이세상의 모든 노트</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li class=book-section-flat><a href=/docs/mystudy/>My Study</a><ul><li><input type=checkbox id=section-58fc894b574437fe14022c5b25f1f586 class=toggle>
<label for=section-58fc894b574437fe14022c5b25f1f586 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/>Algorithm Note</a></label><ul><li><input type=checkbox id=section-1e75b983b0c0ae94e61cd0216d4b17b4 class=toggle>
<label for=section-1e75b983b0c0ae94e61cd0216d4b17b4 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/>Part 2</a></label><ul><li><input type=checkbox id=section-27b18a3105a86ff5267791a1f9a266d5 class=toggle>
<label for=section-27b18a3105a86ff5267791a1f9a266d5 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/>3. 그리디 알고리즘</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/1%EC%9D%B4%EB%90%A0%EB%95%8C%EA%B9%8C%EC%A7%80/>1이될때까지</a></li><li><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/%EC%88%AB%EC%9E%90%EC%B9%B4%EB%93%9C%EA%B2%8C%EC%9E%84/>숫자카드게임</a></li><li><a href=/docs/mystudy/algorithm-note/part2/3_%EA%B7%B8%EB%A6%AC%EB%94%94/%ED%81%B0%EC%88%98%EC%9D%98%EB%B2%95%EC%B9%99/>큰수의법칙</a></li></ul></li><li><input type=checkbox id=section-fdd914078db00724cc0dbb3e4bd9596a class=toggle>
<label for=section-fdd914078db00724cc0dbb3e4bd9596a class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/>4. 구현</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EA%B2%8C%EC%9E%84-%EA%B0%9C%EB%B0%9C/>게임 개발</a></li><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EC%83%81%ED%95%98%EC%A2%8C%EC%9A%B0/>상하좌우</a></li><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EC%8B%9C%EA%B0%81/>시각</a></li><li><a href=/docs/mystudy/algorithm-note/part2/4_%EA%B5%AC%ED%98%84/%EC%99%95%EC%8B%A4%EC%9D%98%EB%82%98%EC%9D%B4%ED%8A%B8/>왕실의나이트</a></li></ul></li><li><input type=checkbox id=section-daf303d7d6cb80ddf1cbab873234ba79 class=toggle>
<label for=section-daf303d7d6cb80ddf1cbab873234ba79 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/>5. DFS & BFS</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/%EB%AF%B8%EB%A1%9C%ED%83%88%EC%B6%9C/>미로탈출</a></li><li><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/%EC%9D%8C%EB%A3%8C%EC%88%98-%EC%96%BC%EB%A0%A4-%EB%A8%B9%EA%B8%B0/>음료수 얼려 먹기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/5_dfs_bfs/datastructure/>자료구조 기초</a></li></ul></li><li><input type=checkbox id=section-a9bcd1b1eda6489baa1f5be05a33c66a class=toggle>
<label for=section-a9bcd1b1eda6489baa1f5be05a33c66a class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/>6. 정렬</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%84%B1%EC%A0%81%EC%9D%B4%EB%82%AE%EC%9D%80%EC%88%9C%EC%84%9C%EB%A1%9C/>성적이낮은순서로</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%9C%84%EC%97%90%EC%84%9C%EC%95%84%EB%9E%98%EB%A1%9C/>위에서아래로</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EA%B3%84%EC%88%98%EC%A0%95%EB%A0%AC/>계수정렬</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%82%BD%EC%9E%85%EC%A0%95%EB%A0%AC/>삽입정렬</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%EC%84%A0%ED%83%9D%EC%A0%95%EB%A0%AC/>선택정렬</a></li><li><a href=/docs/mystudy/algorithm-note/part2/6_%EC%A0%95%EB%A0%AC/%EC%A0%95%EB%A0%AC%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/%ED%80%B5%EC%A0%95%EB%A0%AC/>퀵정렬</a></li></ul></li><li><input type=checkbox id=section-272928fe3909806eb9caa1656eb333db class=toggle>
<label for=section-272928fe3909806eb9caa1656eb333db class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/>7. 이진탐색</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/%EB%96%A1%EB%B3%B6%EC%9D%B4%EB%96%A1%EB%A7%8C%EB%93%A4%EA%B8%B0/>떡볶이떡만들기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/%EB%B6%80%ED%92%88%EC%B0%BE%EA%B8%B0/>부품찾기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/7_%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89/%EC%A7%95%EA%B2%80%EB%8B%A4%EB%A6%AC%EA%B1%B4%EB%84%88%EA%B8%B0/>징검다리건너기</a></li></ul></li><li><input type=checkbox id=section-3845c016ad78684dc4c62b9ba5d8fdea class=toggle>
<label for=section-3845c016ad78684dc4c62b9ba5d8fdea class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/>8. DP</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/1%EB%A1%9C%EB%A7%8C%EB%93%A4%EA%B8%B0/>1로만들기</a></li><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EA%B0%9C%EB%AF%B8%EC%A0%84%EC%82%AC/>개미전사</a></li><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%B0%94%EB%8B%A5%EA%B3%B5%EC%82%AC/>바닥공사</a></li><li><a href=/docs/mystudy/algorithm-note/part2/8_%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%ED%9A%A8%EC%9C%A8%EC%A0%81%EC%9D%B8%ED%99%94%ED%8F%90%EA%B5%AC%EC%84%B1/>효율적인화폐구성</a></li></ul></li><li><input type=checkbox id=section-7bb752c81e98a01db39dc44606af7428 class=toggle>
<label for=section-7bb752c81e98a01db39dc44606af7428 class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part2/9_%EC%B5%9C%EB%8B%A8%EA%B2%BD%EB%A1%9C/>9. 최단경로</a></label><ul></ul></li></ul></li><li><input type=checkbox id=section-9745f3d5cacde06709c284e151f6a1fc class=toggle>
<label for=section-9745f3d5cacde06709c284e151f6a1fc class="flex justify-between"><a href=/docs/mystudy/algorithm-note/part3/>Part 3</a></label><ul><li><input type=checkbox id=section-ee551e150b9c2fcce288d1dd4c42830f class=toggle>
<label for=section-ee551e150b9c2fcce288d1dd4c42830f class="flex justify-between"><a role=button>그리디 알고리즘</a></label><ul><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EA%B3%B1%ED%95%98%EA%B8%B0-%ED%98%B9%EC%9D%80-%EB%8D%94%ED%95%98%EA%B8%B0/>곱하기 혹은 더하기</a></li><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EB%A7%8C%EB%93%A4%EC%88%98%EC%97%86%EB%8A%94%EA%B8%88%EC%95%A1/>만들수없는금액</a></li><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EB%AA%A8%ED%97%98%EA%B0%80%EA%B8%B8%EB%93%9C/>모험가길드</a></li><li><a href=/docs/mystudy/algorithm-note/part3/11_greedy/%EB%B3%BC%EB%A7%81%EA%B3%B5%EA%B3%A0%EB%A5%B4%EA%B8%B0/>볼링공고르기</a></li></ul></li></ul></li><li><a href=/docs/mystudy/algorithm-note/prime_number_code/>소수 관련 코드</a></li></ul></li><li><a href=/docs/mystudy/deep-learning-study/alexnet/ class=active>Alexnet</a></li><li><a href=/docs/mystudy/deep-learning-study/historical_review/>Historical Review</a></li><li><a href=/docs/mystudy/deep-learning-study/readme/>Readme</a></li><li><input type=checkbox id=section-38ffddebf7582461e83409a2c47fb38e class=toggle>
<label for=section-38ffddebf7582461e83409a2c47fb38e class="flex justify-between"><a href=/docs/mystudy/hugo-blog/>Hugo로 github 블로그 만들기</a></label><ul><li><a href=/docs/mystudy/hugo-blog/1_%EC%84%A4%EC%B9%98/>셋팅 및 시작</a></li><li><a href=/docs/mystudy/hugo-blog/2_%EC%BB%A8%ED%85%90%EC%B8%A0%EC%97%B0%EA%B2%B0/>컨텐츠 연결</a></li><li><a href=/docs/mystudy/hugo-blog/3_%EC%9E%90%EB%8F%99%EC%97%85%EB%A1%9C%EB%93%9C/>자동 업로드</a></li></ul></li></ul></li><li class=book-section-flat><a href=/docs/memo/>메모장</a><ul><li><input type=checkbox id=section-5fc2a3e6c3f0bb3e387d832e14caf471 class=toggle>
<label for=section-5fc2a3e6c3f0bb3e387d832e14caf471 class="flex justify-between"><a href=/docs/memo/commands/>자주 쓰는 명령어들</a></label><ul><li><input type=checkbox id=section-d950e99a0f455f739769627ccfc093a5 class=toggle>
<label for=section-d950e99a0f455f739769627ccfc093a5 class="flex justify-between"><a href=/docs/memo/commands/conda/>Conda</a></label><ul><li><a href=/docs/memo/commands/conda/virtual_env/>가상환경 관련</a></li></ul></li><li><input type=checkbox id=section-8b8f38f21ab5e47cb17ec8315d924ccc class=toggle>
<label for=section-8b8f38f21ab5e47cb17ec8315d924ccc class="flex justify-between"><a href=/docs/memo/commands/etc/>Etc</a></label><ul><li><a href=/docs/memo/commands/etc/docker/>Docker</a></li><li><a href=/docs/memo/commands/etc/python-parameter/>python 실행파일 인자값 받기</a></li><li><a href=/docs/memo/commands/etc/python-venv/>python3 venv 사용법</a></li><li><a href=/docs/memo/commands/etc/python-server/>python3 서버열기</a></li><li><a href=/docs/memo/commands/etc/vscode_shortcuts/>VSCode 단축키</a></li><li><a href=/docs/memo/commands/etc/terminal_theme/>터미널 테마</a></li></ul></li><li><input type=checkbox id=section-ff8716a4de3cf13572a8d774da607979 class=toggle>
<label for=section-ff8716a4de3cf13572a8d774da607979 class="flex justify-between"><a href=/docs/memo/commands/linux/>Linux</a></label><ul><li><a href=/docs/memo/commands/linux/gpu/>GPU 관련</a></li><li><a href=/docs/memo/commands/linux/screen/>Ubuntu Screen 명령어</a></li><li><a href=/docs/memo/commands/linux/background/>백그라운드 관련</a></li><li><a href=/docs/memo/commands/linux/zip_tar_gz/>압축 관련</a></li><li><a href=/docs/memo/commands/linux/file_dir/>파일 생성/이동/복사/삭제</a></li></ul></li><li><input type=checkbox id=section-347fea21d799c667c50b28271bbdc289 class=toggle>
<label for=section-347fea21d799c667c50b28271bbdc289 class="flex justify-between"><a href=/docs/memo/commands/poetry/>Poetry</a></label><ul><li><a href=/docs/memo/commands/poetry/poetry_start/>Poetry 시작하기</a></li><li><a href=/docs/memo/commands/poetry/virtual_env/>가상환경 관련</a></li><li><a href=/docs/memo/commands/poetry/export/>내보내기 (requirements.txt)</a></li><li><a href=/docs/memo/commands/poetry/dependency/>의존성 관련</a></li></ul></li><li><input type=checkbox id=section-e7b11a2ea78b363aa19aefb5f0e12701 class=toggle>
<label for=section-e7b11a2ea78b363aa19aefb5f0e12701 class="flex justify-between"><a href=/docs/memo/commands/git/>Git 관련</a></label><ul><li><a href=/docs/memo/commands/git/clone/>clone 관련</a></li><li><a href=/docs/memo/commands/git/cancel/>commit 취소</a></li><li><a href=/docs/memo/commands/git/credential/>credential 관련</a></li><li><a href=/docs/memo/commands/git/submodule/>서브모듈 관련</a></li><li><a href=/docs/memo/commands/git/initial_setup/>초기설정 관련</a></li></ul></li></ul></li><li><input type=checkbox id=section-a438d1db608f6bac90d78927055599ed class=toggle>
<label for=section-a438d1db608f6bac90d78927055599ed class="flex justify-between"><a href=/docs/memo/freq-used-code/>자주 쓰는 코드들</a></label><ul><li><a href=/docs/memo/freq-used-code/histogram/>간단한 히스토그램 python</a></li><li><a href=/docs/memo/freq-used-code/warnings/>경고 무시 python</a></li><li><a href=/docs/memo/freq-used-code/time/>시간 측정 python</a></li><li><a href=/docs/memo/freq-used-code/file_zip/>파일 압축 python</a></li><li><a href=/docs/memo/freq-used-code/file_open/>파일 읽기 python</a></li></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Alexnet</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#dataset-imagenet>Dataset: ImageNet</a></li><li><a href=#architecture>Architecture</a><ul><li><a href=#relu-비선형-활성화-함수>ReLU 비선형 활성화 함수</a></li><li><a href=#여러-gpu로-학습>여러 GPU로 학습</a></li><li><a href=#lrn-local-response-normalization>LRN (Local Response Normalization)</a></li><li><a href=#overlapping-pooling>Overlapping Pooling</a></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=alexnet>AlexNet
<a class=anchor href=#alexnet>#</a></h1><p>논문 요약 정리
<a href=https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf>논문</a></p><h2 id=abstract>Abstract
<a class=anchor href=#abstract>#</a></h2><ul><li>ImageNet LSVRC-2010 (1,200,000장의 고해상도 이미지들)를 1000개의 클래스로 분류하는 CNN 모델</li><li>기존 SOTA보다 향상된 성능</li><li>6천만개의 파라미터, 65만개의 뉴런으로 이루어져있고, 5개의 Conv-layer와 3개의 FC-layer로 구성되어있다. (최종은 1000-way softmax)</li><li>빠르게 훈련시키기 위해 비포화 뉴런과 GPU 구현을 사용</li><li>FC-layer에서 오버피팅을 줄이기 위해 dropout 방법 적용</li><li>또한, Alexnet의 변형은 ILSVRC-2012에서 오류율 15.3%로 우승한 딥러닝 신경망 아키텍처이다.</li></ul><h2 id=introduction>Introduction
<a class=anchor href=#introduction>#</a></h2><ul><li>이 논문의 기여도<ul><li>ImageNet데이터로 훈련한 CNN모델로 이 데이터셋에 대한 최고의 성능에 달성</li><li>2D conv에 최적화된 GPU 구현과 공개</li><li>성능을 향상시키고 훈련시간을 단축시키는 몇 가지 특징들이 있다 (Section 3)</li><li>오버피팅을 방지하는 몇 가지 기술들 (Section 4)</li></ul></li><li>이당시 2개의 GTX 580 3GB GPUs로 훈련했을 때, 5~6일 소요됐다.</li></ul><h2 id=dataset-imagenet>Dataset: ImageNet
<a class=anchor href=#dataset-imagenet>#</a></h2><ul><li>약 22,000개의 카테고리로 이루어진 1천5백만개 이상의 라벨이 있는 고해상도 이미지이다.</li><li>top-5 error rate는 뭐지?</li><li>ImageNet은 다양한 해상도의 이미지로 구성되어있지만, AlexNet은 일정한 차원으로 입력해야 하므로, 256x256 고정으로 다운샘플해야 한다.</li><li>직사각형 이미지에 대해서, 짧은 변을 256으로 resize하고, 중앙 256x256을 잘라내는 작업을 했음.</li></ul><h2 id=architecture>Architecture
<a class=anchor href=#architecture>#</a></h2><ul><li>Conv-layer 5개 + FC-layer 3개로 구성</li></ul><h3 id=relu-비선형-활성화-함수>ReLU 비선형 활성화 함수
<a class=anchor href=#relu-%eb%b9%84%ec%84%a0%ed%98%95-%ed%99%9c%ec%84%b1%ed%99%94-%ed%95%a8%ec%88%98>#</a></h3><p>$$
f(x) = max(0,\space x)
$$</p><ul><li>활성화 함수로 표준은 $f(x) = tanh(x)$ 또는 $f(x) = (1+e^{-x})^{-1}$를 쓰는 것이다.</li><li>경사하강법의 측면에서, 포화 비선형성<em>saturating nonlinearities</em>은 비포화 비선형성<em>non-saturating nonlinearity</em> ($f(x) = max(0,\space x)$, ReLU)보다 느리다.</li><li>위 수식으로 비선형성을 가진 뉴런을 ReLU라고 한다. <em>Rectified Linear Units</em></li><li>ReLU를 사용한 Deep-CNN은 tanh를 사용한 똑같은 Deep-CNN보다 몇배는 빠르다.</li></ul><h3 id=여러-gpu로-학습>여러 GPU로 학습
<a class=anchor href=#%ec%97%ac%eb%9f%ac-gpu%eb%a1%9c-%ed%95%99%ec%8a%b5>#</a></h3><ul><li>GTX 580 GPU 하나는 3GB 메모리밖에 없어, 학습할 수 있는 네트워크의 최대 크기가 제한된다.</li><li>120만개 훈련데이터는 1개의 GPU보다 훨씬 큰 네트워크에서 훈련시킬 수 있다(?)</li><li>그래서 2개의 GPU에 걸쳐 신경망을 분포시킴 (?)</li><li>현재 GPU는 크로스 GPU 병렬화에 특히 적합하다. 왜냐하면, 서로의 메모리를 호스트 시스템 메모리를 거치지 않고 직접 읽어들이고, 쓸 수 있기 때문이다.</li><li>여기서 사용하는 병렬화 방식은 각 GPU에 뉴런을 절반만 배치하며, GPU가 특정 계층에서만 통신한다는 추가 기술이 있다. 예를 들어, layer 3의 뉴런들은 input을 layer 2의 모든 커널 맵에서 가져오지만, layer 4는 input을 같은 GPU에 있는 layer 3의 커널 맵들에서만 가져온다.</li><li>연결 패턴을 선택하는 것은 교차 검증의 문제이지만, 이를 통해 계산량의 허용 가능한 부분이 될 때까지 통신량을 정확하게 조정할 수 있습니다</li><li>2개의 GPU로 학습시킨 신경망이 약간 더 빨리 끝났다.</li></ul><h3 id=lrn-local-response-normalization>LRN (Local Response Normalization)
<a class=anchor href=#lrn-local-response-normalization>#</a></h3><ul><li>ReLU는 포화 방지를 위해 input 정규화가 필요하지 않다는 장점이 있다.</li><li>적어도 몇 훈련 샘플이 ReLU에 양수를 입력한다면, 뉴런에서 학습이 발생할 것이다.</li><li>로컬 정규화가 일반화에 도움이 된다는 것을 발견했다.</li></ul><p><strong>ChatGPT로 정리한 내용</strong></p><ul><li>정규화 기법 중 하나</li><li>LRN 은 활성화 맵 내의 각 위치에서 주변의 값들을 사용하여 정규화를 수행.</li><li>목적: 활성화 맵의 각 요소를 해당 위치에서 주변의 값들을 정규화함으로써, 네트워크의 일반화 성능을 향상시키기 위한 목적으로 도입되었습니다.</li><li>$b_{x,y,i}$는 정규화된 활성화 맵의 한 요소, $a_{x,y,i}$는 원래의 활성화 맵 값.</li><li>효과: LRN을 통해 활성화 값이 어떤 위치에서 다른 필터들의 활성화 값에 대해 정규화되므로, 더 강력한 활성화 패턴을 학습하고 일반화 성능을 향상시킬 수 있습니다.</li><li>AlexNet에서는 LRN가 합성곱 계층 뒤에 적용되었으며, 이로인해 전체 네트워크의 성능이 향상되었습니다.</li><li>LRN은 현재는 주로 사용되지 않는 표준 정규화 기법 중 하나이지만, AlexNet에서 처음 도입되어 성능 향상에 기여한 중요한 요소 중 하나였다.</li></ul><h3 id=overlapping-pooling>Overlapping Pooling
<a class=anchor href=#overlapping-pooling>#</a></h3></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#introduction>Introduction</a></li><li><a href=#dataset-imagenet>Dataset: ImageNet</a></li><li><a href=#architecture>Architecture</a><ul><li><a href=#relu-비선형-활성화-함수>ReLU 비선형 활성화 함수</a></li><li><a href=#여러-gpu로-학습>여러 GPU로 학습</a></li><li><a href=#lrn-local-response-normalization>LRN (Local Response Normalization)</a></li><li><a href=#overlapping-pooling>Overlapping Pooling</a></li></ul></li></ul></nav></div></aside></main></body></html>